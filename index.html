<html>
  <head><title>International Workshop on Arm-based HPC: Practice and Experience (IWAHPCE-2025)</title>
   <link href="style.css" rel="stylesheet" />
  </head>
  <body>
    <table style="width:1000px;margin:0px">
      <tr><td style="width:300px;margin:0px;background-color:#000000;">
	  <center><img src="text899.png"></center>
	</td><td style="width:10px;margin:0px"></td>
	<td>
	  <div class="title">
	    International Workshop on Arm-based HPC: Practice and Experience (IWAHPCE-2025)</div><br>
	    &nbsp;<br>
	  to be held in conjunction with The International Conference on High Performance Computing in Asia-Pacific Region (<a href="https://event1.nchc.org.tw/hpcasia2025/">HPC Asia 2025</a>), Hsinchu, Taiwan, Feb.19-21, 2025.<br>
	  	    &nbsp;<br>
	  <!--------------------------------------------->
	  <div class="subtitle">Workshop Overview</div><br>
This workshop aims to provide the opportunity to share the practice and experience of high-performance computing systems using the Arm architecture and their performance and applications.The last few years have seen an explosion of 64-bit Arm-based processors targeted toward server and infrastructure workloads, often specializing in a specific domain such as HPC, cloud, and machine learning. Fujitsu’s A64FX and Marvell’s ThunderX2 have been used in several large-scale HPC systems, and Amazon’s Graviton2 has been adopted by Amazon EC2. Moreover, Amazon’s Graviton3, NVIDIA Grace CPU Superchip, and SiPearl’s Rhea system-on-chip are recently announced or become accessible.Sharing the practice and experiences using these Arm-based processors will contribute to advancing high-performance computing technology for newly designed systems using these new emerging Arm-based processors.<br><br>
	  <!--------------------------------------------->
	  <div class="subtitle">Program</div><br>
		&nbsp;&nbsp;&nbsp;-&nbsp;<table>
			<tr><td>09:00-09:10</td><td>Miwako Tsuji</td><td>Opening Remarks</td></tr>
		<tr><td>09:10-10:00</td>Koichi Shirahata<td></td><td><b>Invited Talk: Fugaku-LLM: A Large Language Model Trained on the Supercomputer Fugaku</b><br>
Abstract: 
While not initially designed for large-scale deep learning models like Large Language Models (LLMs), Japan's flagship supercomputer, Fugaku, provided a unique opportunity. This work details the optimization of deep learning frameworks for distributed parallel execution on Fugaku, creating a high-performance computing environment for LLM training. A novel LLM was trained from scratch using a large dataset primarily focused on Japanese text.
</td></tr>
		<tr><td></td><td></td><td></td></tr>
		<tr><td></td><td></td><td></td></tr>
		<tr><td></td><td></td><td></td></tr>
		<tr><td></td><td></td><td></td></tr>
		<tr><td></td><td></td><td></td></tr>
		
		</table>
09:10-10:00 Koichi Shirahata, Invited talk (title: TBA)
10:00-10:30 Shinji  Sumimoto, Takashi  Arakawa, Yoshio  Sakaguchi, Hiroya  Matsuba, Satoshi  Ohshima, Hisashi  Yashiro, Toshihiro  Hanawa, Kengo  Nakajima, "Accelerating Heterogeneous Coupling Computing with WaitIO Using RDMA"
10:30-11:00 Break
11:00-11:30 Oscar  Hernandez, Thomas  Wang, Wael  Elwasif, Filippo  Spiga, Francesca  Tartaglione, Markus  Eisenbach, Ross  Miller, "Preliminary Study on Fine-Grained Power and Energy Measurements on Grace Hopper GH200 with Open-Source Performance Tools"
11:30-12:00 David  Carlson, Nikolay  Simakov, Rodrigo  Ristow Hadlich, Anthony  Curtis, Joshua  Martin, Gaurav  Verma, Smeet  Chheda, Firat  Coskun, Raul  Gonzalez, Daniel  Wood, Feng  Zhang, Robert  Harrison, Eva  Siegmann, "The AmpereOne A192-32X in Perspective: Benchmarking a New Standard",
12:00-12:30 Xuanzhengbo  Ren, Yuta  Kawai, Hirofumi  Tomita, Seiya  Nishizawa, Takahiro  Katagiri, Tetsuya  Hoshino, Daichi  Mukunoki, Masatoshi  Kawai, Toru  Nagai, "Performance Evaluation of Loop Body Splitting for Fast Modal Filtering in SCALE-DG on A64FX",
	  <!--------------------------------------------->		
	  <div class="subtitle">Topics</div>
	  <br>
In particular, this workshop will focus on the following topics of interest:<br>
&nbsp;&nbsp;&nbsp;-&nbsp;HPC Applications<br> 
&nbsp;&nbsp;&nbsp;-&nbsp;Performance Analysis, Performance Modeling & Measurement<br>
&nbsp;&nbsp;&nbsp;-&nbsp;SVE Vectorization analysis<br>
&nbsp;&nbsp;&nbsp;-&nbsp;Programming Models & System Softoware<br>
&nbsp;&nbsp;&nbsp;-&nbsp;Networking and accelerators such as GPUs<br>
&nbsp;&nbsp;&nbsp;-&nbsp;Artificial Intelligence and Machine Learning<br>
&nbsp;&nbsp;&nbsp;-&nbsp;Emerging Technologies<br>
	  <br>
	  <!--------------------------------------------->
	  <div class="subtitle">Paper Submissions</div>
	  <br>
All papers must be original and not simultaneously submitted to another journal or conference. The following paper categories are welcome:<br>
&nbsp;&nbsp;&nbsp;-&nbsp;Full papers Manuscripts must be at most 18 pages in one-column submission PDF format including figures and references<br>
&nbsp;&nbsp;&nbsp;-&nbsp;Short papers Manuscripts must be at most 10 pages in one-column submission PDF format including figures and references<br>
The paper format is described in the Paper Submission section of <a href="https://event1.nchc.org.tw/hpcasia2025/papers.html">HPCAsia2025</a><br>
Please note that the paper format for the submission (one-column) is different from the one of the camera ready (2-column). Fore more detail, please refer https://www.acm.org/publications/authors/submissions<br>
All submissions will be peer-reviewed by the PC members. Papers will be accepted to presentations in a workshop. The review process is double-blind. Please do NOT include the name of authors, etc... <br>
			  <br>
	  <!--------------------------------------------->
	  <div class="subtitle">Important Dates</div>
	  <br>
&nbsp;&nbsp;&nbsp;-&nbsp;Full Paper Submission (via <s>Linklings</s>Easychair): 23th Dec 2024<br>
&nbsp;&nbsp;&nbsp;-&nbsp;Notification: 12th Jan 2025<br>
&nbsp;&nbsp;&nbsp;-&nbsp;Camera ready: 15th Jan 2025<br>
			  <br>
	  <!--------------------------------------------->

          <div class="subtitle">Submission Site</div>
	  <br>
			<u><a href="https://easychair.org/conferences/?conf=iwahpce2025">https://easychair.org/conferences/?conf=iwahpce2025</a></u> <br>
			  <br>
	  <!--------------------------------------------->
	  <!--------------------------------------------->

          <div class="subtitle">Registration and Open Access Fee</div>
	  <br>
&nbsp;&nbsp;&nbsp;-&nbsp;At least one author must register for the conference<br>
	  &nbsp;&nbsp;&nbsp;-&nbsp;Based on the ACM's new Open Access publication policy, the <b>publication fee</b> will be contacted with and collected by ACM directly from the authors.<br>
	  &nbsp;&nbsp;&nbsp;-&nbsp;For more details about the ACM Open Access policy and fee, please refer <a href="https://authors.acm.org/open-access">here</a> and <a href="https://www.acm.org/publications/icps/author-guidance">here</a>. 
	  <br>
&nbsp;&nbsp;&nbsp;-&nbsp;However, if your institution is a member of the ACM Open program, the paper will be published with no charge , as indicated on the web site. The list of participating institutions of ACM Open can be viewed https://libraries.acm.org/acmopen/open-participants.   
	  <br>
			  <br>
	  <!--------------------------------------------->

          <div class="subtitle">Organizers and Program Committee</div>
	  <br>
		<b>Organizer and Workshop Chair</b><br>
    Miwako Tsuji, RIKEN R-CCS<br>
    Eva Siegmann, Stony Brook University<br>
    Filippo Spiga, NVIDIA<br>
<br>
<b>Program Committee</b><br>
		Conrad Hillairet &nbsp;&nbsp;Arm<br>
Csaba Csoma &nbsp;&nbsp;ASW<br>
Estela Suarez &nbsp;&nbsp;JSC<br>
Eva Siegmann&nbsp;&nbsp;Stony Brook University<br>
Fabio Banchelli &nbsp;&nbsp;BSC<br>
Filippo Spiga&nbsp;&nbsp;NVIDIA<br>
Gilles Fourestey &nbsp;&nbsp;EPFL<br>
Jens Domke &nbsp;&nbsp;RIKEN R-CCS<br>
John Cazes &nbsp;&nbsp;TACC<br>
Luca Fedeli &nbsp;&nbsp;CEA<br>
Min Li &nbsp;&nbsp;Huawei<br>
Miwako Tsuji&nbsp;&nbsp; RIKEN R-CCS<br>
Tetsuya Odajima &nbsp;&nbsp;Fujitsu<br>
Wael Elwas&nbsp;&nbsp;ORNL<br>
Yuetsu Kodama&nbsp;&nbsp; RIKEN R-CCS<br>
	</td>
  </tr>
  </table>
  </body>
  
</html>
